{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **tomato juice dataset**\n",
    "<br>` 'quality' is the target feature for classification `\n",
    "<br>` the other features are chemical properties of our product `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_S34U5S-i69d"
   },
   "source": [
    "**Import the main libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "_import the local library_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add parent folder path where lib folder is\n",
    "import sys\n",
    "if \"..\" not in sys.path:import sys; sys.path.insert(0, '..') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mylib import show_labels_dist, show_metrics, bias_var_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9IZetEZ8jQJm"
   },
   "source": [
    "**Import the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## file path: windows style\n",
    "df = pd.read_csv('..\\\\datasets\\\\tomatjus.csv')\n",
    "\n",
    "## file path: unix style\n",
    "#df = pd.read_csv('../datasets/tomatjus.csv')\n",
    "\n",
    "# shape method gives the dimensions of the dataset\n",
    "print('Dataset dimensions: {} rows, {} columns'.format(\n",
    "    df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "***\n",
    "**Data Preparation and EDA** (unique to this dataset)\n",
    "* _Check for missing values_\n",
    "* _Quick visual check of unique values_\n",
    "* _Split the classification feature out of the dataset_\n",
    "* _Check column names of categorical attributes ( for get_dummies() )_\n",
    "* _Check column names of numeric attributes ( for Scaling )_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Let's skip the checking_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification target feature**\n",
    "<br>_Make it a multi-class problem, using text labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  divide into classes by giving a range for quality\n",
    "##  Make it a multi-class problem: {3,4,5} {6} {7.8}\n",
    "bins = (2, 5, 6, 8)\n",
    "group_names = ['Average', 'Premium', 'Special']\n",
    "df['quality'] = pd.cut(df['quality'], bins = bins, labels = group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the classification feature out of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature being predicted (\"the Right Answer\")\n",
    "labels_col = 'quality'\n",
    "y = df[labels_col]\n",
    "\n",
    "## Features used for prediction \n",
    "# pandas has a lot of rules about returning a 'view' vs. a copy from slice\n",
    "# so we force it to create a new dataframe \n",
    "X = df.copy()\n",
    "X.drop(labels_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "***\n",
    "**<br>Create Test // Train Datasets**\n",
    "> Split X and y datasets into Train and Test subsets,<br>keeping relative proportions of each class (stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=50, \n",
    "                                                    stratify=y)\n",
    "# train_test_split does random selection, \n",
    "#      so we should reset the dataframe indexes\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test._is_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**<br>Scaling** comes _after_ test // train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeri = X.select_dtypes(include=['float64','int64']).columns\n",
    "print(numeri.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the Numeric columns \n",
    "# StandardScaler range: -1 to 1, MinMaxScaler range: zero to 1\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# sklearn docs say \n",
    "#   \"Don't cheat - fit only on training data, then transform both\"\n",
    "#   fit() expects 2D array: reshape(-1, 1) for single col or (1, -1) single row\n",
    "\n",
    "for i in numeri:\n",
    "    arr = np.array(X_train[i])\n",
    "    scale = MinMaxScaler().fit(arr.reshape(-1, 1))\n",
    "    X_train[i] = scale.transform(arr.reshape(len(arr),1))\n",
    "\n",
    "    arr = np.array(X_test[i])\n",
    "    X_test[i] = scale.transform(arr.reshape(len(arr),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**<br>Classifier Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare list\n",
    "models = []\n",
    "\n",
    "##  --  Linear  --  ## \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "models.append ((\"LogReg\",LogisticRegression())) \n",
    "#from sklearn.linear_model import SGDClassifier \n",
    "#models.append ((\"StocGradDes\",SGDClassifier())) \n",
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "#models.append((\"LinearDA\", LinearDiscriminantAnalysis())) \n",
    "#from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis \n",
    "#models.append((\"QuadraticDA\", QuadraticDiscriminantAnalysis())) \n",
    "\n",
    "##  --  Support Vector  --  ## \n",
    "#from sklearn.svm import SVC \n",
    "#models.append((\"SupportVectorClf\", SVC())) \n",
    "#from sklearn.svm import LinearSVC \n",
    "#models.append((\"LinearSVC\", LinearSVC())) \n",
    "#from sklearn.linear_model import RidgeClassifier\n",
    "#models.append ((\"RidgeClf\",RidgeClassifier())) \n",
    "\n",
    "##  --  Non-linear  --  ## \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "models.append ((\"DecisionTree\",DecisionTreeClassifier())) \n",
    "#from sklearn.naive_bayes import GaussianNB \n",
    "#models.append ((\"GaussianNB\",GaussianNB())) \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "models.append((\"K-NNeighbors\", KNeighborsClassifier())) \n",
    "\n",
    "##  --  Ensemble: bagging  --  ## \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "models.append((\"RandomForest\", RandomForestClassifier())) \n",
    "##  --  Ensemble: boosting  --  ## \n",
    "#from sklearn.ensemble import AdaBoostClassifier \n",
    "#models.append((\"AdaBoost\", AdaBoostClassifier())) \n",
    "#from sklearn.ensemble import GradientBoostingClassifier \n",
    "#models.append((\"GradientBoost\", GradientBoostingClassifier())) \n",
    "\n",
    "##  --  NeuralNet (simplest)  --  ## \n",
    "#from sklearn.neural_network import MLPClassifier \n",
    "#models.append((\"MultiLayerPtron\", MLPClassifier())) \n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<br>Target Label Distributions** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from our local library\n",
    "show_labels_dist(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "**<br>Fit and Predict** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate each model in turn\n",
    "results = []\n",
    "\n",
    "print('macro average: unweighted mean per label')\n",
    "print('weighted average: support-weighted mean per label')\n",
    "print('MCC: correlation between prediction and ground truth')\n",
    "print('     (+1 perfect, 0 random prediction, -1 inverse)\\n')\n",
    "\n",
    "for name, clf in models:\n",
    "    trs = time()\n",
    "    print('Confusion Matrix:', name)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    ygx = clf.predict(X_test)\n",
    "    results.append((name, ygx))\n",
    "    \n",
    "    tre = time() - trs\n",
    "    print (\"Run Time {} seconds\".format(round(tre,2)) + '\\n')\n",
    "    \n",
    "# Easy way to ensure that the confusion matrix rows and columns\n",
    "#   are labeled exactly as the classifier has coded the classes\n",
    "#   [[note the _ at the end of clf.classes_ ]]\n",
    "\n",
    "    show_metrics(y_test, ygx, clf.classes_)   # from our local library\n",
    "    print('\\nParameters: ', clf.get_params(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**Bias - Variance Decomposition** (standard block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from our local library\n",
    "# reduce (cross-validation) folds for faster results\n",
    "folds = 20\n",
    "for name, clf in models:\n",
    "    print('Bias // Variance Decomposition:', name)\n",
    "    bias_var_metrics(X_train,X_test,y_train,y_test,clf,folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg",
    "tags": []
   },
   "source": [
    "**<br>Imports** for model comparison - CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Default scorer for classification is sklearn.metrics.accuracy_score \n",
    "# For imbalanced classification, the accuracy score is often uninformative\n",
    "# For the list of options see\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "# average for each label weighted by support \n",
    "#        (number of true instances for each label)\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "eval_metric = ['wtd.avg.accuracy', \n",
    "               'balanced_accuracy', \n",
    "               'wtd.avg.f1_score', \n",
    "               'f1_weighted']\n",
    "\n",
    "# for graphs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "***\n",
    "**Model Comparison: Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "# a variation of KFold that returns stratified folds,  \n",
    "#   preserving the percentage of samples for each class\n",
    "\n",
    "# ----  Cross Validation  ---- #\n",
    "# number of rounds\n",
    "folds = 3\n",
    "\n",
    "# choose a metric\n",
    "scorer = eval_metric[1]\n",
    "# ----    ---- #\n",
    "\n",
    "# define the strategy\n",
    "skf = StratifiedKFold(shuffle=True, random_state = 11, n_splits=folds)\n",
    "\n",
    "from time import time\n",
    "trs = time()\n",
    "print('KFold CV: %i folds with scoring = %s \\n\\t timer started' % (folds, scorer))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    print(name, end='')    # no newline at the end\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=skf, scoring=scorer)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \":\\t%s = %0.3f +/- (%0.3f)\" % (scorer, \n",
    "                                         cv_results.mean(), \n",
    "                                         cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "tre = time() - trs\n",
    "print (\"\\tRun Time {} seconds\".format(round(tre,2)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot model comparison\n",
    "# One box and whisker plot for each algorithmâ€™s sample of results.\n",
    "\n",
    "ttl = scorer + ' Comparison'\n",
    "print(\"The box shows the middle 50 percent of the data,\\n\"\n",
    "      \"the orange line in the middle of each box shows the median of the sample,\\n\"\n",
    "      \"and the green triangle in each box shows the mean of the sample.\")\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(ttl)\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results, showmeans=True)\n",
    "#ax.set_xticklabels(names)\n",
    "plt.show()\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual model per-fold results\n",
    "from yellowbrick.model_selection import cv_scores\n",
    "for name, model in models:\n",
    "    viz = cv_scores(model, X_train, y_train, cv=skf, scoring=scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpzuyj7gxwCg"
   },
   "source": [
    "***\n",
    "**Model Comparison: Bias - Variance Decomposition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "## bias_variance_decomp() requires \n",
    "##    1. numpy ndarrays\n",
    "##    2. numeric targets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# slow because it does num_rounds (default=200) bootstrap cross validation\n",
    "folds = 12\n",
    "\n",
    "from time import time\n",
    "trs = time()\n",
    "print('Bias-Variance: Model Comparison \\n\\t timer started')\n",
    "\n",
    "ytrain = LabelEncoder().fit_transform(y_train)\n",
    "ytest = LabelEncoder().fit_transform(y_test)\n",
    "\n",
    "# for graphs\n",
    "rx = np.arange(len(models))       # the x locations for the groups\n",
    "\n",
    "cn, bias, var, err = [], [], [], []\n",
    "for name, clf in models:\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        clf, X_train.values, ytrain, X_test.values, ytest, \n",
    "        loss='0-1_loss', num_rounds=folds, random_seed=150)\n",
    "    err.append(avg_expected_loss)\n",
    "    bias.append(avg_bias)\n",
    "    var.append(avg_var)\n",
    "    cn.append(name)\n",
    "    \n",
    "    print(name,end='')    # no newline at the end\n",
    "    msg=\": Bias: %0.3f  Variance: %0.3f  E.loss: %0.3f\" % (avg_bias, avg_var, avg_expected_loss)\n",
    "    print(msg)\n",
    "    \n",
    "tre = time() - trs\n",
    "print (\"\\tRun Time {} seconds\".format(round(tre,2)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(rx, err, 'b', label = 'total_error')\n",
    "ax.plot(rx, bias, 'k', label = 'bias')\n",
    "ax.plot(rx, var, 'y', label = 'variance')\n",
    "ax.legend()\n",
    "ax.set_xticks(rx)\n",
    "ax.set_title('Bias-Variance Decomposition')\n",
    "plt.show()\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked bar plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(rx, err, color = 'b', width= 0.35)\n",
    "ax.bar(rx, bias, color = 'g', width= 0.35)\n",
    "ax.bar(rx, var, color = 'r', width= 0.35)\n",
    "ax.legend(labels=['E.loss', 'Bias', 'Var'])\n",
    "ax.set_title('Bias-Variance Decomposition')\n",
    "ax.set_xticks(rx)\n",
    "plt.show()\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
